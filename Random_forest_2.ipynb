{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cafbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from glob import glob # this will help us download the data in order to visualize it\n",
    "#These functions will be vital in making the CNN\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "#For some image processing\n",
    "import keras.preprocessing.image as kpi\n",
    "#This will be important for processing the metadata\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f72dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting with down loading the meta data\n",
    "data_location = '/fs/ess/PAS2038/PHYSICS5680_OSU/student_data/armitage'\n",
    "Meta = pd.DataFrame()\n",
    "Meta_name = data_location + '/train.csv'\n",
    "Meta = pd.read_csv(Meta_name,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b358b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta['Random'] = np.random.randint(0,1000,size = len(Meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_data = Meta.iloc[:,1:13]\n",
    "#Add this for reference\n",
    "Meta_data['Random'] = Meta['Random']\n",
    "Meta_data['Pawpularity'] = Meta['Pawpularity']\n",
    "Meta = Meta_data\n",
    "Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Splitting into X(Features) Y(Pawpularity)\n",
    "X_Meta = Meta.iloc[:,1:13].to_numpy()\n",
    "Y_Meta = Meta['Pawpularity']\n",
    "\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X_Meta,Y_Meta.values, test_size=0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2927e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Meta.iloc[:,1:13]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array(Y_test)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966e1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def calc_performance_multi(true_labels,predicted_labels):\n",
    "#\n",
    "# Get the total number of unique labels\n",
    "    num_labels = len(set(true_labels))\n",
    "    confusionMatrix = nested_defaultdict(int,num_labels)\n",
    "#\n",
    "# Initialize all columns and rows\n",
    "    for true_class in set(true_labels):\n",
    "        for pred_class in set(true_labels):\n",
    "            confusionMatrix[true_class][pred_class] = 0\n",
    "# \n",
    "# Now calculate the confusion matrix\n",
    "    for i in range(len(predicted_labels)):\n",
    "        true_class = true_labels[i]      # this is either 0 or 1\n",
    "        pred_class = predicted_labels[i]\n",
    "        confusionMatrix[true_class][pred_class] += 1\n",
    "#\n",
    "# Get the recall, precision, ands F1 for each individual label\n",
    "# - return both the \"string report\" (which you can print)\n",
    "# - and the \"dictionary report\" (which you can use for averages and so on)\n",
    "    report = classification_report(true_labels,predicted_labels)\n",
    "    report_dict = classification_report(true_labels,predicted_labels,output_dict=True)\n",
    "#\n",
    "    results = {\"confusionMatrix\":confusionMatrix,\"report\":report,\"report_dict\":report_dict}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dccdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fitter_multi(estimator,X_train,y_train,X_test,y_test):\n",
    "#\n",
    "# Now fit to our training set\n",
    "    estimator.fit(X_train,y_train)\n",
    "#\n",
    "# Now predict the classes and get the score for our traing set\n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "\n",
    "#\n",
    "# Now predict the classes and get the score for our test set\n",
    "    y_test_pred = estimator.predict(X_test)\n",
    " \n",
    "    results_test = calc_performance_multi(y_test,y_test_pred)\n",
    "    results_train = calc_performance_multi(y_train,y_train_pred)\n",
    "#\n",
    "    return results_train,results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20853494",
   "metadata": {},
   "source": [
    "# Doing the random forest regressor here, but running to check max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "dfError = []\n",
    "\n",
    "#Here is the random forest regressor which aims to train on the RMSE, from the Meta Data\n",
    "for depth in range (5,20):\n",
    "    estimator = RandomForestRegressor(n_estimators=100,random_state=42,max_depth= depth)\n",
    "    estimator.fit(X_train,Y_train)\n",
    "    \n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "    y_test_pred = estimator.predict(X_test)\n",
    "    \n",
    "    train_RMSE = np.sqrt(mean_squared_error(Y_train,y_train_pred))\n",
    "    test_RMSE = np.sqrt(mean_squared_error(Y_test,y_test_pred))\n",
    "    dfError.append({'max_depth':depth,\n",
    "                             'train_RMSE':train_RMSE,\n",
    "                             'test_RMSE':test_RMSE\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dfError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436349f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, x='max_depth', y=['train_RMSE','test_RMSE'], title='RMSE vs Iteration')\n",
    "fig.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3afab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffeatures= pd.DataFrame()\n",
    "dffeatures['Features'] = ['Eyes','Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur','Random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffeatures[\"Importance\"] = estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc79fef",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(dffeatures,x='Features', y=\"Importance\",\n",
    "                      title='Feature Importance')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracted_Features = pd.read_csv('Copy of Pet_Features.csv',header = None,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracted_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_data['Pawpularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14864c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracted_Features['Pawpularity'] = Meta_data['Pawpularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracted_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf8193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
